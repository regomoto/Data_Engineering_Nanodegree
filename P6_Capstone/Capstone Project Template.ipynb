{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "This project will create a data model that an analytics team can use to gain insights into United States immigration data. \n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Conclusion and Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycountry\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/b6/154fe93072051d8ce7bf197690957b6d0ac9a21d51c9a1d05bd7c6fdb16f/pycountry-19.8.18.tar.gz (10.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.0MB 2.9MB/s eta 0:00:01   22% |███████▍                        | 2.3MB 29.4MB/s eta 0:00:01    54% |█████████████████▋              | 5.5MB 34.7MB/s eta 0:00:01    86% |███████████████████████████▊    | 8.7MB 36.5MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pycountry\n",
      "  Running setup.py bdist_wheel for pycountry ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/a2/98/bf/f0fa1c6bf8cf2cbdb750d583f84be51c2cd8272460b8b36bd3\n",
      "Successfully built pycountry\n",
      "Installing collected packages: pycountry\n",
      "Successfully installed pycountry-19.8.18\n"
     ]
    }
   ],
   "source": [
    "#install if do not have pycountry\n",
    "!pip install pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Imports and installs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pycountry\n",
    "from datetime import datetime, timedelta\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql.functions import udf, col,  trim, initcap, year, month, upper, round, substring, length, when\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from immigration_countries import i94country_name\n",
    "from countries import get_country_code\n",
    "from i94_states import get_state_name, get_state_code\n",
    "\n",
    "# Create spark session\n",
    "spark = SparkSession\\\n",
    ".builder\\\n",
    ".config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\") \\\n",
    ".getOrCreate()\n",
    "\n",
    "# SQL context\n",
    "from pyspark.sql import SQLContext\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Project Scope and Data\n",
    "The objective of this project is to create a data pipeline that will combine datasets from multiple sources into a data model with a star schema. The data model shoud allow users to analyze immigration trends and other descriptive statistics. Analysts should be able to use infomration outside of the immigration dataset, such as data about temperature, US city demographics, and airport data to perform their analyses.\n",
    "\n",
    "To create the star schema model, I will implment a data pipeline that processes data from multiple sources. The data sources I am using can be found at the following links:\n",
    "- [__I94 immigration data:__](https://travel.trade.gov/research/reports/i94/historical/2016.html) US immigration data from the US National Tourism and Trade Office \n",
    "\n",
    "- [__World temperature data:__](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data) Contains CSV files for overall global temperatures and temperatures by city, major city, state, country.\n",
    "\n",
    "- [__US city demographics data:__](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/) Demographics data includes values such as population, race, age, and household size.\n",
    "\n",
    "- [__Airport codes data:__](https://datahub.io/core/airport-codes#data) Contains data related to airports. Airports have three character codes that uniquely identify them. For example, LaGuardia airport's code is LGA.   \n",
    "\n",
    "Using the final data model should allow analysts to answer questions such as:\n",
    "- How many people immigrated from a certain country?\n",
    "- Which US city had the most immigrants in a given time period?\n",
    "- How many people immigrated to each state?\n",
    "- How many immigrants came under each type of visa (student, business, pleasure)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore, Assess, and Clean the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Exploratory Data Anlysis (EDA)\n",
    "\n",
    "I performed exploratory data analysis to determine what is in each file (data types, what each column represents, number or records) and identify any data transformations that need to be performed.\n",
    "\n",
    "EDA was performed on all 4 data sources in separate Python notebook using Pandas. Key takeaways for each dataset:\n",
    "\n",
    "_Immigration data:_\n",
    " - 29 columns\n",
    " - Columns that are integers are being read in as floats. Change these datatypes into integers when creating data model\n",
    " - Dates are not date types. They are also based on SAS dates, which will require extra processing\n",
    "\n",
    "\n",
    "_Demographics data:_\n",
    "- 12 columns\n",
    "- Some columns are floats when they should be integers\n",
    "- Each city has multiple rows of data. For example Birmingham, Alabama has five rows. In each <br>of these rows there are repeat values for most of the columns. Data should be transposed/pivoted so there is only one row per city.\n",
    " - For example, there are 5 race categoires (White, Black, Asian, Hispanic or Latio, and ). The dataset will have separate rows for each <br>of these races for every city. If we transpose/pivot the data, then each row will correspond with 1 city with values in each race column.\n",
    "\n",
    "_Airport data:_\n",
    "- 12 columns\n",
    "- Can derive continent from region column. \n",
    "- Can also derive country from the region column. Good since region has no null values, but country has some nulls\n",
    "- Many rows had nulls in the continent and iso_country columns. This is because the values are \"NA\". We need to process <br>these with escape characters to prevent improper reading of this field. \n",
    "\n",
    "_Temperature data:_\n",
    "- 5 columns\n",
    "- AverageTemperature represents the average temperature for a given month. This is recorded in a date column with a date value for the first of the month\n",
    "- Add a country code and state code that uses a 2 digit ISO code for uniform naming. This will allow us to link/join datasets\n",
    " - Need to do a little customization/manual linking for some countries due to differing naming conventions between the dataset and standard lookup directory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Cleaning Steps\n",
    "\n",
    "Before creating an ETL scirpt, identify what steps are needed to clean and transform the data into what we want to use in our data model:\n",
    "1. Immigration\n",
    "- Convert the following columns from float/double to integer: i94yr, i94mo, i94cit, i94res, i94mode, i94bir, i94visa\n",
    "- Convert date in arrdate and depdate. Currently in SAS date format and need to convert to a date type object that reflects the correct date\n",
    "2. Demographic data\n",
    "- Convert the following columns from float/double to integer: Male Population, Female Population, Total Population, Total Population, Number of Veterans, Foreign-born\n",
    "- Transpose demographics data\n",
    " - Each row represents a single city\n",
    " - Add columns for each \"Race\" value\n",
    " - Add percent columns for all of the count columns based on the total population of the city. Since cities have differing sizes, it would be good to view these as percentages\n",
    "3. Aiport data\n",
    "-  Add a columns that has a 2 digit ISO country code for uniform naming. This will allow us to link/join datasets\n",
    "- Need to do a little customization/manual linking for some countries due to differing naming conventions between the dataset and standard lookup directory (see EDA \n",
    "4. Temperature data\n",
    "- Add a columns that has a 2 digit ISO country code for uniform naming. This will allow us to link/join datasets\n",
    "- Need to do a little customization/manual linking for some countries due to differing naming conventions between the dataset and standard lookup directory (see EDA steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 1) Immigration Data Cleaning\n",
    "- Convert from float/double to integer: i94yr, i94mo, i94cit, i94res, i94mode, i94bir, i94visa\n",
    "- Convert date in arrdate and depdate. Currently in SAS date format and need to convert to regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#import data into spark dataframes\n",
    "immigration_spark = spark.read.load('./sas_data/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|    cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|5748517.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     CA|20582.0|  40.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1976.0|10292016|     F|  null|     QF|9.495387003E10|00011|      B1|\n",
      "|5748518.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     NV|20591.0|  32.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1984.0|10292016|     F|  null|     VA|9.495562283E10|00007|      B1|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_spark.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define a function that can handle converting SAS dates\n",
    "def convert_datetime(x):\n",
    "    try:\n",
    "        start = datetime(1960, 1, 1)\n",
    "        return start + timedelta(days=int(x))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "datetime_from_sas = udf(lambda x: convert_datetime(x), T.DateType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Convert data types and process SAS dates\n",
    "# This takes in the i94res column, and uses the 3 digit number to get a name for the country.\n",
    "# It uses the provided data dictionary from the immigration dataset\n",
    "\n",
    "immigration_clean = immigration_spark \\\n",
    "    .withColumn('cicid', immigration_spark['cicid'].cast('integer')) \\\n",
    "    .withColumn('i94yr', immigration_spark['i94yr'].cast('integer')) \\\n",
    "    .withColumn('i94mon', immigration_spark['i94mon'].cast('integer')) \\\n",
    "    .withColumn('i94cit', immigration_spark['i94cit'].cast('integer')) \\\n",
    "    .withColumn('i94res', immigration_spark['i94res'].cast('integer')) \\\n",
    "    .withColumn('i94mode', immigration_spark['i94mode'].cast('integer')) \\\n",
    "    .withColumn('i94bir', immigration_spark['i94bir'].cast('integer')) \\\n",
    "    .withColumn('i94visa', immigration_spark['i94visa'].cast('integer')) \\\n",
    "    .withColumn('arrival_date', datetime_from_sas(col('arrdate'))) \\\n",
    "    .withColumn('departure_date', datetime_from_sas('depdate')) \\\n",
    "    .withColumn('i94res_name', trim(i94country_name('i94res'))) \\\n",
    "    .withColumn('i94res_isocode', get_country_code(upper(col('i94res_name'))))\\\n",
    "    .withColumn('i94addr_name', get_state_name(col('i94addr')))\\\n",
    "    .withColumn('trip_duration', (col('depdate') - col('arrdate')).cast('integer'))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cicid', 'int'),\n",
       " ('i94yr', 'int'),\n",
       " ('i94mon', 'int'),\n",
       " ('i94cit', 'int'),\n",
       " ('i94res', 'int'),\n",
       " ('i94port', 'string'),\n",
       " ('arrdate', 'double'),\n",
       " ('i94mode', 'int'),\n",
       " ('i94addr', 'string'),\n",
       " ('depdate', 'double'),\n",
       " ('i94bir', 'int'),\n",
       " ('i94visa', 'int'),\n",
       " ('count', 'double'),\n",
       " ('dtadfile', 'string'),\n",
       " ('visapost', 'string'),\n",
       " ('occup', 'string'),\n",
       " ('entdepa', 'string'),\n",
       " ('entdepd', 'string'),\n",
       " ('entdepu', 'string'),\n",
       " ('matflag', 'string'),\n",
       " ('biryear', 'double'),\n",
       " ('dtaddto', 'string'),\n",
       " ('gender', 'string'),\n",
       " ('insnum', 'string'),\n",
       " ('airline', 'string'),\n",
       " ('admnum', 'double'),\n",
       " ('fltno', 'string'),\n",
       " ('visatype', 'string'),\n",
       " ('arrival_date', 'date'),\n",
       " ('departure_date', 'date'),\n",
       " ('i94res_name', 'string'),\n",
       " ('i94res_isocode', 'string'),\n",
       " ('i94addr_name', 'string'),\n",
       " ('trip_duration', 'int')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration_clean.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Selecting columns\n",
    "immigration_clean = immigration_clean\\\n",
    "    .select(col('cicid').alias('id'), col('i94mon').alias('month'), col('i94yr').alias('year'),\\\n",
    "            col('arrival_date'), col('departure_date'), col('trip_duration').cast('integer'),\\\n",
    "            col('i94res_isocode').alias('origin_country_code'),\\\n",
    "            col('i94res_name').alias('origin_country'), col('i94mode').alias('transportation_mode'),\\\n",
    "            col('i94addr').alias('us_state'), col('i94addr_name').alias('us_state_name'),\\\n",
    "            col('i94port').alias('port'), col('gender'), col('i94bir').alias('age'), col('airline'),\\\n",
    "            col('i94visa').alias('visa_type'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+----+------------+--------------+-------------+-------------------+--------------+-------------------+--------+-------------+----+------+---+-------+---------+\n",
      "|     id|month|year|arrival_date|departure_date|trip_duration|origin_country_code|origin_country|transportation_mode|us_state|us_state_name|port|gender|age|airline|visa_type|\n",
      "+-------+-----+----+------------+--------------+-------------+-------------------+--------------+-------------------+--------+-------------+----+------+---+-------+---------+\n",
      "|5748517|    4|2016|  2016-04-30|    2016-05-08|            8|                 AU|     AUSTRALIA|                  1|      CA|   California| LOS|     F| 40|     QF|        1|\n",
      "|5748518|    4|2016|  2016-04-30|    2016-05-17|           17|                 AU|     AUSTRALIA|                  1|      NV|       Nevada| LOS|     F| 32|     VA|        1|\n",
      "+-------+-----+----+------------+--------------+-------------+-------------------+--------------+-------------------+--------+-------------+----+------+---+-------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_clean.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- arrival_date: date (nullable = true)\n",
      " |-- departure_date: date (nullable = true)\n",
      " |-- trip_duration: integer (nullable = true)\n",
      " |-- origin_country_code: string (nullable = true)\n",
      " |-- origin_country: string (nullable = true)\n",
      " |-- transportation_mode: integer (nullable = true)\n",
      " |-- us_state: string (nullable = true)\n",
      " |-- us_state_name: string (nullable = true)\n",
      " |-- port: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- visa_type: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_clean.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create temp view to use for Spark SQL\n",
    "immigration_clean.createOrReplaceTempView('immigration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|TotalRows|\n",
      "+---------+\n",
      "|  3096313|\n",
      "+---------+\n",
      "\n",
      "+-----+-------+\n",
      "|month|  Count|\n",
      "+-----+-------+\n",
      "|    4|3096313|\n",
      "+-----+-------+\n",
      "\n",
      "+----+-------+\n",
      "|year|  Count|\n",
      "+----+-------+\n",
      "|2016|3096313|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How many rows are in the data\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT COUNT(*) as TotalRows\n",
    "FROM immigration\n",
    "\"\"\"\n",
    ").show()\n",
    "\n",
    "# How many months are contained in the data?\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT month, COUNT(*) as Count\n",
    "FROM immigration\n",
    "GROUP BY month\n",
    "\"\"\"\n",
    ").show(30)\n",
    "\n",
    "# How many years are contained in the data?\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT year, COUNT(*) as Count\n",
    "FROM immigration\n",
    "GROUP BY year\n",
    "\"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2) Demographics Data Cleaning\n",
    "\n",
    "Convert the collowing columns from float/double to integer: \n",
    "- Male Population, Female Population, Total Population, Total Population, Number of Veterans, Foreign-born\n",
    "\n",
    "Aggregate demographics data:\n",
    "\n",
    "- Each row represents a single city's count for the number a certain race. This results in cities having many rows.\n",
    "- By aggregating the data on race, an individual row can represent one city by having different race columns\n",
    "\n",
    "Add percent columns for all of the count columns based on the total population of the city. Since cities have differing sizes, it would be good to view these as percentages as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import demographics data into Spark dataframe\n",
    "demo_spark = spark.read.csv('./us-cities-demographics.csv', header = True, sep = ';', inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: double (nullable = true)\n",
      " |-- Male Population: integer (nullable = true)\n",
      " |-- Female Population: integer (nullable = true)\n",
      " |-- Total Population: integer (nullable = true)\n",
      " |-- Number of Veterans: integer (nullable = true)\n",
      " |-- Foreign-born: integer (nullable = true)\n",
      " |-- Average Household Size: double (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demo_spark.printSchema()\n",
    "#demo_spark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demo_pivot = demo_spark.groupBy('City','State','Median Age','Male Population', 'Female Population', 'Total Population', 'Number of Veterans',\n",
    "    'Foreign-born', 'Average Household Size', 'State Code')\\\n",
    "    .pivot(\"Race\").sum('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "|      City|       State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|American Indian and Alaska Native|Asian|Black or African-American|Hispanic or Latino| White|\n",
      "+----------+------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "|   Modesto|  California|      35.2|         104852|           106405|          211257|              9855|       39613|                  2.97|        CA|                             4388|19417|                     9869|             85141|166618|\n",
      "|Pittsburgh|Pennsylvania|      32.9|         149690|           154695|          304385|             17728|       28187|                  2.13|        PA|                             2689|21227|                    82248|              9266|208863|\n",
      "+----------+------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demo_pivot.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: double (nullable = true)\n",
      " |-- Male Population: integer (nullable = true)\n",
      " |-- Female Population: integer (nullable = true)\n",
      " |-- Total Population: integer (nullable = true)\n",
      " |-- Number of Veterans: integer (nullable = true)\n",
      " |-- Foreign-born: integer (nullable = true)\n",
      " |-- Average Household Size: double (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- American Indian and Alaska Native: long (nullable = true)\n",
      " |-- Asian: long (nullable = true)\n",
      " |-- Black or African-American: long (nullable = true)\n",
      " |-- Hispanic or Latino: long (nullable = true)\n",
      " |-- White: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demo_pivot.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demo1 = demo_pivot\\\n",
    "    .groupBy('State','State Code')\\\n",
    "    .agg(f.sum('Male Population').alias('MalePopulation'),\\\n",
    "         f.sum('Female Population').alias('FemalePopulation'),\\\n",
    "         f.sum('Total Population').alias('TotalPopulation'),\\\n",
    "         f.sum('Number of Veterans').alias('NumberVeterans'),\\\n",
    "         f.sum('Foreign-born').alias('Foreign-born'),\\\n",
    "         f.sum('American Indian and Alaska Native').alias('AmericanIndianAlaskaNativeTotal'),\\\n",
    "         f.sum('Asian').alias('AsianTotal'),\\\n",
    "         f.sum('Black or African-American').alias('BlackTotal'),\\\n",
    "         f.sum('Hispanic or Latino').alias('HispanicTotal'),\\\n",
    "         f.sum('White').alias('WhiteTotal'),\\\n",
    "         f.avg('Median Age').alias('MedianAge'),\\\n",
    "         f.avg('Average Household Size').alias('AvgHouseholdSize'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------------+----------------+---------------+--------------+------------+-------------------------------+----------+----------+-------------+----------+---------+------------------+\n",
      "|      State|State Code|MalePopulation|FemalePopulation|TotalPopulation|NumberVeterans|Foreign-born|AmericanIndianAlaskaNativeTotal|AsianTotal|BlackTotal|HispanicTotal|WhiteTotal|MedianAge|  AvgHouseholdSize|\n",
      "+-----------+----------+--------------+----------------+---------------+--------------+------------+-------------------------------+----------+----------+-------------+----------+---------+------------------+\n",
      "|Mississippi|        MS|        112147|          130536|         242683|         14792|        4861|                            323|      2587|    167366|         7264|     71645|     33.4|2.5949999999999998|\n",
      "|       Utah|        UT|        530818|          519773|        1050591|         39671|      132819|                          18746|     48801|     21893|       201695|    889798|    30.98|             3.175|\n",
      "+-----------+----------+--------------+----------------+---------------+--------------+------------+-------------------------------+----------+----------+-------------+----------+---------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demo1.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demo2 = demo1\\\n",
    "    .select(col('State'), col('State Code').alias('StateCode'), col('MedianAge'), col('MalePopulation'),\\\n",
    "    col('FemalePopulation'),col('TotalPopulation'), col('NumberVeterans'),col('Foreign-born'),\\\n",
    "    col(\"AvgHouseholdSize\"), col('AmericanIndianAlaskaNativeTotal'), col('AsianTotal'), col('BlackTotal'),\\\n",
    "    col('HispanicTotal'), col('WhiteTotal'))\\\n",
    "    .withColumn('MalePopPercent', round(col('MalePopulation') / col('TotalPopulation'), 4))\\\n",
    "    .withColumn('FemalePopPercent', round(col('FemalePopulation') / col('TotalPopulation'), 4))\\\n",
    "    .withColumn('VeteranPopPercent', round(col('NumberVeterans') / col('TotalPopulation'), 4))\\\n",
    "    .withColumn('ForeignPopPercent', round(col('Foreign-born') / col('TotalPopulation'), 4))\\\n",
    "    .withColumn('Black_pct', round(col('BlackTotal') / col('TotalPopulation'),4))\\\n",
    "    .withColumn('White_pct', round(col('WhiteTotal') / col('TotalPopulation'), 4))\\\n",
    "    .withColumn('Asian_pct', round(col('AsianTotal') / col('TotalPopulation'), 4))\\\n",
    "    .withColumn('Hispanic_pct', round(col('HispanicTotal') / col('TotalPopulation'),4))\\\n",
    "    .withColumn('AmericanIndianAlaskaNative_pct', round(col('AmericanIndianAlaskaNativeTotal') / col('TotalPopulation'),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+---------+--------------+----------------+---------------+--------------+------------+------------------+-------------------------------+----------+----------+-------------+----------+--------------+----------------+-----------------+-----------------+---------+---------+---------+------------+------------------------------+\n",
      "|      State|StateCode|MedianAge|MalePopulation|FemalePopulation|TotalPopulation|NumberVeterans|Foreign-born|  AvgHouseholdSize|AmericanIndianAlaskaNativeTotal|AsianTotal|BlackTotal|HispanicTotal|WhiteTotal|MalePopPercent|FemalePopPercent|VeteranPopPercent|ForeignPopPercent|Black_pct|White_pct|Asian_pct|Hispanic_pct|AmericanIndianAlaskaNative_pct|\n",
      "+-----------+---------+---------+--------------+----------------+---------------+--------------+------------+------------------+-------------------------------+----------+----------+-------------+----------+--------------+----------------+-----------------+-----------------+---------+---------+---------+------------+------------------------------+\n",
      "|Mississippi|       MS|     33.4|        112147|          130536|         242683|         14792|        4861|2.5949999999999998|                            323|      2587|    167366|         7264|     71645|        0.4621|          0.5379|            0.061|             0.02|   0.6896|   0.2952|   0.0107|      0.0299|                        0.0013|\n",
      "|       Utah|       UT|    30.98|        530818|          519773|        1050591|         39671|      132819|             3.175|                          18746|     48801|     21893|       201695|    889798|        0.5053|          0.4947|           0.0378|           0.1264|   0.0208|   0.8469|   0.0465|       0.192|                        0.0178|\n",
      "+-----------+---------+---------+--------------+----------------+---------------+--------------+------------+------------------+-------------------------------+----------+----------+-------------+----------+--------------+----------------+-----------------+-----------------+---------+---------+---------+------------+------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demo2.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "This is a query to see if all states have one row and total population for each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demo2.createOrReplaceTempView('demo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|COUNT|\n",
      "+-----+\n",
      "|   49|\n",
      "+-----+\n",
      "\n",
      "+---------+-----+---------------+\n",
      "|StateCode|COUNT|TotalPopulation|\n",
      "+---------+-----+---------------+\n",
      "|       CA|    1|       24822460|\n",
      "|       TX|    1|       14299983|\n",
      "|       NY|    1|        9815626|\n",
      "|       FL|    1|        6796738|\n",
      "|       IL|    1|        4562312|\n",
      "|       AZ|    1|        4499542|\n",
      "|       NC|    1|        3060199|\n",
      "|       CO|    1|        2935669|\n",
      "|       WA|    1|        2500107|\n",
      "|       OH|    1|        2433689|\n",
      "+---------+-----+---------------+\n",
      "\n",
      "+---------+-----+---------------+\n",
      "|StateCode|COUNT|TotalPopulation|\n",
      "+---------+-----+---------------+\n",
      "+---------+-----+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See how many rows\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT COUNT(*) as COUNT\n",
    "FROM demo\n",
    "\"\"\"\n",
    ").show()\n",
    "\n",
    "# See state code for first 10\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT StateCode, COUNT(*) as COUNT, SUM(TotalPopulation) as TotalPopulation\n",
    "FROM demo\n",
    "GROUP BY StateCode\n",
    "ORDER BY COUNT DESC, TotalPopulation DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    ").show(10)\n",
    "\n",
    "# See which state codes have a count greater than 1\n",
    "# Should return none. If not, then there is an error and should check again\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT StateCode, COUNT(*) as COUNT, SUM(TotalPopulation) as TotalPopulation\n",
    "FROM demo\n",
    "GROUP BY StateCode\n",
    "HAVING COUNT > 1\n",
    "ORDER BY COUNT DESC, TotalPopulation DESC\n",
    "\"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3) Airport Data Cleaning\n",
    "- There are many nulls in the continent column. All are from \"NA\" values being processed as nulls. This is for the continent North America\n",
    "- There are also nulls in the country column. These all have \"NA\" values being processed as nulls. This is for the country Namibia\n",
    "- However, it appears that when using Spark these errors do not occur. Following is to double check that these are automatically read in correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import airport data into Spark dataframe\n",
    "airports_spark = spark.read.csv('./airport-codes_csv.csv', header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|  00A|     heliport|   Total Rf Heliport|          11|       NA|         US|     US-PA|    Bensalem|     00A|     null|       00A|-74.9336013793945...|\n",
      "| 00AA|small_airport|Aero B Ranch Airport|        3435|       NA|         US|     US-KS|       Leoti|    00AA|     null|      00AA|-101.473911, 38.7...|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airports_spark.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Filter dataframe for only US airports\n",
    "# Get the right two characters from iso_region column to get the state values\n",
    "# Fix one erroneous value that has Asia as the continent value for a US airport\n",
    "# Remove rows with us_state values of '-A', since EDA showed there are values with this value and is not a correct value\n",
    "airports_spark = airports_spark\\\n",
    "    .filter(col('iso_country') =='US')\\\n",
    "    .filter(airports_spark.iata_code.isNotNull())\\\n",
    "    .withColumn('us_state', substring(airports_spark.iso_region,-2, 2))\\\n",
    "    .withColumn('continent', when((col('iso_country')=='US') & (col('continent')!='NA'), 'NA').otherwise(col('continent')))\\\n",
    "    .filter(col('us_state') != '-A')\\\n",
    "    .select('iata_code', 'name', 'type', 'elevation_ft', 'us_state')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-------------+------------+--------+\n",
      "|iata_code|                name|         type|elevation_ft|us_state|\n",
      "+---------+--------------------+-------------+------------+--------+\n",
      "|      OCA|Ocean Reef Club A...|small_airport|           8|      FL|\n",
      "|      PQS|Pilot Station Air...|small_airport|         305|      AK|\n",
      "+---------+--------------------+-------------+------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airports_spark.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airports_spark.createOrReplaceTempView('airports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|record_count|\n",
      "+------------+\n",
      "|        2019|\n",
      "+------------+\n",
      "\n",
      "+---------+-----+\n",
      "|iata_code|count|\n",
      "+---------+-----+\n",
      "|      CLG|    2|\n",
      "|      AUS|    2|\n",
      "|      AHT|    2|\n",
      "|      ESP|    2|\n",
      "|      PHL|    2|\n",
      "+---------+-----+\n",
      "\n",
      "+-----+\n",
      "|count|\n",
      "+-----+\n",
      "|   51|\n",
      "+-----+\n",
      "\n",
      "+--------+-----+\n",
      "|us_state|count|\n",
      "+--------+-----+\n",
      "|      AK|  334|\n",
      "|      CA|  157|\n",
      "|      TX|  122|\n",
      "|      FL|   78|\n",
      "|      WA|   55|\n",
      "|      NY|   53|\n",
      "|      MI|   48|\n",
      "|      AZ|   46|\n",
      "|      PA|   44|\n",
      "|      OK|   43|\n",
      "|      WI|   42|\n",
      "|      IL|   41|\n",
      "|      IA|   41|\n",
      "|      OH|   38|\n",
      "|      CO|   38|\n",
      "|      IN|   37|\n",
      "|      GA|   37|\n",
      "|      OR|   36|\n",
      "|      KS|   36|\n",
      "|      MN|   35|\n",
      "|      NC|   34|\n",
      "|      VA|   32|\n",
      "|      NE|   31|\n",
      "|      SC|   31|\n",
      "|      NV|   30|\n",
      "|      AL|   30|\n",
      "|      NM|   30|\n",
      "|      WY|   29|\n",
      "|      AR|   29|\n",
      "|      MO|   29|\n",
      "|      UT|   28|\n",
      "|      MS|   27|\n",
      "|      MT|   27|\n",
      "|      TN|   26|\n",
      "|      LA|   22|\n",
      "|      MA|   22|\n",
      "|      HI|   22|\n",
      "|      ME|   19|\n",
      "|      NJ|   18|\n",
      "|      SD|   18|\n",
      "|      KY|   18|\n",
      "|      ID|   17|\n",
      "|      MD|   17|\n",
      "|      ND|   15|\n",
      "|      WV|   14|\n",
      "|      NH|   12|\n",
      "|      CT|    9|\n",
      "|      VT|    7|\n",
      "|      RI|    6|\n",
      "|      DC|    5|\n",
      "|      DE|    4|\n",
      "+--------+-----+\n",
      "\n",
      "+---------+----+----+------------+--------+\n",
      "|iata_code|name|type|elevation_ft|us_state|\n",
      "+---------+----+----+------------+--------+\n",
      "+---------+----+----+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How many airports in this dataset?\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT count(iata_code) AS record_count\n",
    "FROM airports\n",
    "\"\"\"\n",
    ").show()\n",
    "\n",
    "# IS iata_code unique?\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT iata_code, count(iata_code) AS count\n",
    "FROM airports\n",
    "GROUP BY iata_code\n",
    "HAVING count > 1\n",
    "\"\"\"\n",
    ").show()\n",
    "\n",
    "\n",
    "# How many states are in this dataset?\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT count(distinct(us_state)) AS count\n",
    "FROM airports\n",
    "\"\"\"\n",
    ").show()\n",
    "\n",
    "# How many airports per state\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT us_state, count(iata_code) AS count\n",
    "FROM airports\n",
    "GROUP BY us_state\n",
    "ORDER BY count DESC\n",
    "\"\"\"\n",
    ").show(52)\n",
    "\n",
    "# State_code \"-A\" sticks out. Look at records with this state code \n",
    "# Query below should return nothing since filtered data on this parameter\n",
    "\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT *\n",
    "FROM airports\n",
    "WHERE us_state = '-A'\n",
    "\"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4a) Temperature Data (By State)\n",
    "- Filter by Country = United States since we are interested in getting state temperatures of US states. This data <br>will be joined with the immigration data to provide information about the temperature of states that people are traveling to.\n",
    "- Create a state abbreveation columns so that data can be joined using a standardized code.\n",
    "- AverageTemperature column has the most recent temperature values with a date of 9/1/2013. \n",
    "- This data set is until 9/1/2013. However, immigration data is only for April 2016. Therefore, cannot join on individual dates <br>or even by year. Therefore, will be joining based on the average temperature for the state since the year 2000. Since <br>climate changes occur, having the most recent temperatures would be more useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import temperature data into Spark dataframe\n",
    "state_temp = spark.read.csv('./GlobalLandTemperaturesByState.csv', header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+-----------------------------+-----+-------+\n",
      "|                 dt|AverageTemperature|AverageTemperatureUncertainty|State|Country|\n",
      "+-------------------+------------------+-----------------------------+-----+-------+\n",
      "|1855-05-01 00:00:00|            25.544|                        1.171| Acre| Brazil|\n",
      "|1855-06-01 00:00:00|            24.228|                        1.103| Acre| Brazil|\n",
      "+-------------------+------------------+-----------------------------+-----+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state_temp.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: timestamp (nullable = true)\n",
      " |-- AverageTemperature: double (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state_temp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create year, month, and country code columns\n",
    "# filter by month = 4 since our fact table only has April 2016 data\n",
    "# Want to see average temps for this month since 2000\n",
    "state_temp_clean = state_temp\\\n",
    "    .filter(col('Country') == 'United States')\\\n",
    "    .withColumn('year', year(col('dt')))\\\n",
    "    .withColumn('month', month(col('dt')))\\\n",
    "    .withColumn('state_code', get_state_code(state_temp['State']))\\\n",
    "    .filter(col('year') > 1999)\\\n",
    "    .filter(col('month') == 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+-----------------------------+-------+-------------+----+-----+----------+\n",
      "|                 dt|AverageTemperature|AverageTemperatureUncertainty|  State|      Country|year|month|state_code|\n",
      "+-------------------+------------------+-----------------------------+-------+-------------+----+-----+----------+\n",
      "|2000-04-01 00:00:00|            16.032|                         0.11|Alabama|United States|2000|    4|        AL|\n",
      "|2001-04-01 00:00:00|            18.517|                        0.129|Alabama|United States|2001|    4|        AL|\n",
      "+-------------------+------------------+-----------------------------+-------+-------------+----+-----+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state_temp_clean.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "state_temp_agg = state_temp_clean\\\n",
    "    .groupBy('State','state_code')\\\n",
    "    .agg(round(f.avg('AverageTemperature'),2).alias('AvgTemp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+-------+\n",
      "|       State|state_code|AvgTemp|\n",
      "+------------+----------+-------+\n",
      "| Mississippi|        MS|  18.38|\n",
      "|South Dakota|        SD|   7.74|\n",
      "+------------+----------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state_temp_agg.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "state_temp_agg.createOrReplaceTempView('state_temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|TotalStates|\n",
      "+-----------+\n",
      "|         51|\n",
      "+-----------+\n",
      "\n",
      "+-----+-----+\n",
      "|State|COUNT|\n",
      "+-----+-----+\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See how many states there are. Should be 51 (50 states and Washington + DC)\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT COUNT(DISTINCT(State)) AS TotalStates\n",
    "FROM state_temp\n",
    "\"\"\"\n",
    ").show()\n",
    "\n",
    "# See if states have more than one row. Should return none/be blank\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT State, count(AvgTemp) AS COUNT\n",
    "FROM state_temp\n",
    "GROUP BY State\n",
    "HAVING COUNT > 1\n",
    "\"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4b) Temperature Data (By Country)\n",
    "- Notes are similar to part 4a for state temperatures. However, need to give countries a country code instead for joining.\n",
    "- This data will be used to provide temperature information about countries outside of the US where travelers are coming from. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "country_temp = spark.read.csv('./GlobalLandTemperaturesByCountry.csv', header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create year, month, and country code columns\n",
    "# Filter out non-US columns since the country temperature data will be joined using i94res from the immigration data. \n",
    "# i94res represents the country where the person is coming from\n",
    "country_temp_clean = country_temp\\\n",
    "    .filter(col('AverageTemperature').isNotNull())\\\n",
    "    .withColumn('year', year(col('dt')))\\\n",
    "    .withColumn('month', month(col('dt')))\\\n",
    "    .withColumn('country_code', get_country_code(upper(col('Country'))))\\\n",
    "    .filter(col('year') > 1999)\\\n",
    "    .filter(col('month') == 4)\\\n",
    "    .filter(col('country_code') != '99999')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+-----------------------------+-----------+----+-----+------------+\n",
      "|                 dt|AverageTemperature|AverageTemperatureUncertainty|    Country|year|month|country_code|\n",
      "+-------------------+------------------+-----------------------------+-----------+----+-----+------------+\n",
      "|2000-04-01 00:00:00|             18.44|                        0.522|Afghanistan|2000|    4|          AF|\n",
      "|2001-04-01 00:00:00|             17.23|           0.5720000000000001|Afghanistan|2001|    4|          AF|\n",
      "+-------------------+------------------+-----------------------------+-----------+----+-----+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_temp_clean.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "country_temp_agg = country_temp_clean\\\n",
    "    .groupBy('Country','country_code')\\\n",
    "    .agg(round(f.avg('AverageTemperature'), 2).alias('AvgTemp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+-------+\n",
      "|  Country|country_code|AvgTemp|\n",
      "+---------+------------+-------+\n",
      "|   Sweden|          SE|   2.72|\n",
      "|Indonesia|          ID|  26.48|\n",
      "+---------+------------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_temp_agg.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "country_temp_agg.createOrReplaceTempView('country_temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|Country|COUNT|\n",
      "+-------+-----+\n",
      "+-------+-----+\n",
      "\n",
      "+-----+\n",
      "|COUNT|\n",
      "+-----+\n",
      "|  220|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify one country per row. Should not have groups with counts greater than 1 and return none\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT Country, count(AvgTemp) AS COUNT\n",
    "FROM country_temp\n",
    "GROUP BY Country\n",
    "HAVING COUNT > 1\n",
    "\"\"\"\n",
    ").show()\n",
    "\n",
    "\n",
    "# Get the number of countries contained in the dataset. Filtered for countries without a country code\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT count(distinct(Country)) AS COUNT\n",
    "FROM country_temp\n",
    "\"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "The data model uses a star schema with fact and dimension tables. A star schema is a simple schema design that makes performing analytics queries very easy. An analytics team will benefit from using a star schema by allowing for simpler queries with easier to understand join logic from the business perspective. It will also boost query performance.\n",
    "\n",
    "The final star schema data model will have the following fact and dimension tables (also available in data dictioanry with more detail):\n",
    "\n",
    "__FACT TABLE__: \n",
    "\n",
    "- id, Month, Year,Arrival_Date, Departure_Date, Trip_Duration, Visa_Type, Gender, Age, <br>US_State_Name, State_Temp, State_Population, State_Male_Population, State_Female_Population, <br>Origin_Country, Origin_Country_Temp, Airport_Name, Airport_State, Airline, Mode_Transportation\n",
    "\n",
    "<br>\n",
    "\n",
    "__DIMENSION TABLES__:\n",
    "\n",
    "__*Immigration Table*__:\n",
    "- id, month, year, arrival_date, departure_date, trip_duration, origin_country_code, origin_country,<br> transportation_mode, us_state, us_state_name, port, gender, age, airline, visa_type\n",
    "\n",
    "\n",
    "__*Airport Table*__:\n",
    "- iata_code, name, type, elevation_ft, us_state\n",
    "\n",
    "__*Demographics Table*__:\n",
    "- State, StateCode, MedianAge, MalePopulation, FemalePopulation, TotalPopulation, NumberVeterans, <br>Foreign-born, AvgHouseholdSize, AmericanIndianAlaskaNativeTotal, AsianTotal, BlackTotal,<br> HispanicTotal, WhiteTotal, MalePopPercent, FemalePopPercent, VeteranPopPercent, TotalPopulation,<br> ForeignPopPercent, Black_pct, White_pct, Asian_pct, Hispanic_pct, AmericanIndianAlaskaNative_pct\n",
    "\n",
    "__*State Temperature Table*__:\n",
    "- State, state_code, AvgTemp \n",
    "__*Country Temperature Table*__:\n",
    "- Country, country_code, AvgTemp\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "The following are the steps needed to pipeline the data into the data model\n",
    "1. Create dimension tables using the cleaned data\n",
    "2. Create the fact table from the cleaned immigration data\n",
    "3. Write fact table to a parquet file\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create temporary views to allow the use of Spark SQL\n",
    "\n",
    "immigration_clean.createOrReplaceTempView('immigration')\n",
    "demo2.createOrReplaceTempView('demo')\n",
    "airports_spark.createOrReplaceTempView('airports')\n",
    "state_temp_agg.createOrReplaceTempView('state_temp')\n",
    "country_temp_agg.createOrReplaceTempView('country_temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- arrival_date: date (nullable = true)\n",
      " |-- departure_date: date (nullable = true)\n",
      " |-- trip_duration: integer (nullable = true)\n",
      " |-- origin_country_code: string (nullable = true)\n",
      " |-- origin_country: string (nullable = true)\n",
      " |-- transportation_mode: integer (nullable = true)\n",
      " |-- us_state: string (nullable = true)\n",
      " |-- us_state_name: string (nullable = true)\n",
      " |-- port: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- visa_type: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_clean.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- elevation_ft: integer (nullable = true)\n",
      " |-- us_state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airports_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- State: string (nullable = true)\n",
      " |-- StateCode: string (nullable = true)\n",
      " |-- MedianAge: double (nullable = true)\n",
      " |-- MalePopulation: long (nullable = true)\n",
      " |-- FemalePopulation: long (nullable = true)\n",
      " |-- TotalPopulation: long (nullable = true)\n",
      " |-- NumberVeterans: long (nullable = true)\n",
      " |-- Foreign-born: long (nullable = true)\n",
      " |-- AvgHouseholdSize: double (nullable = true)\n",
      " |-- AmericanIndianAlaskaNativeTotal: long (nullable = true)\n",
      " |-- AsianTotal: long (nullable = true)\n",
      " |-- BlackTotal: long (nullable = true)\n",
      " |-- HispanicTotal: long (nullable = true)\n",
      " |-- WhiteTotal: long (nullable = true)\n",
      " |-- MalePopPercent: double (nullable = true)\n",
      " |-- FemalePopPercent: double (nullable = true)\n",
      " |-- VeteranPopPercent: double (nullable = true)\n",
      " |-- ForeignPopPercent: double (nullable = true)\n",
      " |-- Black_pct: double (nullable = true)\n",
      " |-- White_pct: double (nullable = true)\n",
      " |-- Asian_pct: double (nullable = true)\n",
      " |-- Hispanic_pct: double (nullable = true)\n",
      " |-- AmericanIndianAlaskaNative_pct: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demo2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- State: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- AvgTemp: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state_temp_agg.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country: string (nullable = true)\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- AvgTemp: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_temp_agg.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Selecting fields and joining datasets\n",
    "\n",
    "immigration_final = spark.sql(\n",
    "\"\"\"\n",
    "SELECT \n",
    "       i.id AS id,\n",
    "       i.year AS Year,\n",
    "       i.month AS Month,\n",
    "       i.arrival_date AS Arrival_Date,\n",
    "       i.departure_date AS Departure_Date,\n",
    "       i.trip_duration AS Trip_Duration,\n",
    "       i.visa_type AS Visa_Type, \n",
    "       i.gender AS Gender,\n",
    "       i.age AS Age,\n",
    "       i.us_state_name AS US_State_Name,\n",
    "       s.AvgTemp AS State_Temp,\n",
    "       d.TotalPopulation AS State_Population,\n",
    "       d.MalePopPercent AS State_Male_Population,\n",
    "       d.FemalePopPercent AS State_Female_Population,\n",
    "       i.origin_country as Origin_Country,\n",
    "       c.AvgTemp AS Origin_Country_Temp,\n",
    "       a.name AS Airport_Name,\n",
    "       a.us_state AS Airport_State,\n",
    "       i.airline AS Airline,\n",
    "       i.transportation_mode AS Mode_Transportation\n",
    "FROM immigration i \n",
    "    JOIN demo d on i.us_state = d.StateCode\n",
    "    JOIN airports a on i.port = a.iata_code\n",
    "    JOIN state_temp s on i.us_state = s.state_code\n",
    "    JOIN country_temp c on i.origin_country_code = c.country_code\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+------------+--------------+-------------+---------+------+---+-------------+----------+----------------+---------------------+-----------------------+--------------+-------------------+--------------------+-------------+-------+-------------------+\n",
      "|     id|Year|Month|Arrival_Date|Departure_Date|Trip_Duration|Visa_Type|Gender|Age|US_State_Name|State_Temp|State_Population|State_Male_Population|State_Female_Population|Origin_Country|Origin_Country_Temp|        Airport_Name|Airport_State|Airline|Mode_Transportation|\n",
      "+-------+----+-----+------------+--------------+-------------+---------+------+---+-------------+----------+----------------+---------------------+-----------------------+--------------+-------------------+--------------------+-------------+-------+-------------------+\n",
      "|5748525|2016|    4|  2016-04-30|    2016-05-07|            7|        2|     M| 27|      Florida|     21.49|         6796738|               0.4762|                 0.5131|   NEW ZEALAND|              11.51|William P Hobby A...|           TX|     NZ|                  1|\n",
      "+-------+----+-----+------------+--------------+-------------+---------+------+---+-------------+----------+----------------+---------------------+-----------------------+--------------+-------------------+--------------------+-------------+-------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_final.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- Arrival_Date: date (nullable = true)\n",
      " |-- Departure_Date: date (nullable = true)\n",
      " |-- Trip_Duration: integer (nullable = true)\n",
      " |-- Visa_Type: integer (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- US_State_Name: string (nullable = true)\n",
      " |-- State_Temp: double (nullable = true)\n",
      " |-- State_Population: long (nullable = true)\n",
      " |-- State_Male_Population: double (nullable = true)\n",
      " |-- State_Female_Population: double (nullable = true)\n",
      " |-- Origin_Country: string (nullable = true)\n",
      " |-- Origin_Country_Temp: double (nullable = true)\n",
      " |-- Airport_Name: string (nullable = true)\n",
      " |-- Airport_State: string (nullable = true)\n",
      " |-- Airline: string (nullable = true)\n",
      " |-- Mode_Transportation: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_final.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Write dataframe to parquet file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "immigration_final.write.parquet(\"immigration_fact_table\", mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+------------+--------------+-------------+---------+------+---+-------------+----------+----------------+---------------------+-----------------------+--------------+-------------------+--------------------+-------------+-------+-------------------+\n",
      "|     id|Year|Month|Arrival_Date|Departure_Date|Trip_Duration|Visa_Type|Gender|Age|US_State_Name|State_Temp|State_Population|State_Male_Population|State_Female_Population|Origin_Country|Origin_Country_Temp|        Airport_Name|Airport_State|Airline|Mode_Transportation|\n",
      "+-------+----+-----+------------+--------------+-------------+---------+------+---+-------------+----------+----------------+---------------------+-----------------------+--------------+-------------------+--------------------+-------------+-------+-------------------+\n",
      "|5748525|2016|    4|  2016-04-30|    2016-05-07|            7|        2|     M| 27|      Florida|     21.49|         6796738|               0.4762|                 0.5131|   NEW ZEALAND|              11.51|William P Hobby A...|           TX|     NZ|                  1|\n",
      "|5748527|2016|    4|  2016-04-30|    2016-05-02|            2|        2|     M| 44|Massachusetts|      7.92|         2015457|               0.4841|                 0.5159|        PANAMA|               27.8|   Lakefront Airport|           LA|     UA|                  1|\n",
      "|5748532|2016|    4|  2016-04-30|    2016-05-07|            7|        2|     F| 53|      Florida|     21.49|         6796738|               0.4762|                 0.5131|        PANAMA|               27.8|Miami Internation...|           FL|     CM|                  1|\n",
      "+-------+----+-----+------------+--------------+-------------+---------+------+---+-------------+----------+----------------+---------------------+-----------------------+--------------+-------------------+--------------------+-------------+-------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read back data to double check\n",
    "spark.read.parquet(\"immigration_fact_table\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Possible Analytic Queries\n",
    "\n",
    "The following are possible analytic queries that can be performed using the fact table above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_final.createOrReplaceTempView('final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In April 2016, people arrived in the United States with the following types of visas:\n",
      "+---------+-------+\n",
      "|Visa_Type|  Count|\n",
      "+---------+-------+\n",
      "|        1| 268572|\n",
      "|        2|1061322|\n",
      "|        3|  18726|\n",
      "+---------+-------+\n",
      "\n",
      "Visa types are:\n",
      "1 = Business\n",
      "2 = Pleasure\n",
      "3 = Student\n",
      "Appears most people traveling for pleasure\n",
      "Top five airports people traveled through:\n",
      "+--------------------+------+\n",
      "|             Airport| Count|\n",
      "+--------------------+------+\n",
      "|Miami Internation...|325002|\n",
      "|San Fernando Airport|147535|\n",
      "|Orlando Executive...|142905|\n",
      "|   Lakefront Airport|132360|\n",
      "|William P Hobby A...| 94591|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For the given timeframe of the dataset, how many people immigrated on each type of visa?\n",
    "\n",
    "print('In April 2016, people arrived in the United States with the following types of visas:')\n",
    "\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT Visa_Type, count(Year) as Count\n",
    "FROM final\n",
    "GROUP BY Visa_Type\n",
    "ORDER BY Visa_Type\n",
    "\"\"\"\n",
    ").show(4)\n",
    "print('Visa types are:\\n1 = Business\\n2 = Pleasure\\n3 = Student\\nAppears most people traveling for pleasure')\n",
    "\n",
    "# The top five airports that travlers came through were the following:\n",
    "\n",
    "print('Top five airports people traveled through:')\n",
    "\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT Airport_Name AS Airport, count(Year) as Count\n",
    "FROM final\n",
    "GROUP BY Airport_Name\n",
    "ORDER BY Count DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    ").show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top countries that people immigrated from:\n",
      "+--------------------+------+\n",
      "|      Origin_Country| Count|\n",
      "+--------------------+------+\n",
      "|      UNITED KINGDOM|181801|\n",
      "|MEXICO Air Sea, a...| 95298|\n",
      "|              BRAZIL| 86469|\n",
      "|             GERMANY| 85277|\n",
      "|              FRANCE| 75344|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The top countries that people came from\n",
    "\n",
    "print('The top countries that people immigrated from:')\n",
    "\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT Origin_Country, count(Year) as Count\n",
    "FROM final\n",
    "GROUP BY Origin_Country\n",
    "ORDER BY Count DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The country where most visitors came from was the United Kingdom. They traveled to the following states most often:\n",
      "+-------------+-----+\n",
      "|US_State_Name|Count|\n",
      "+-------------+-----+\n",
      "|      Florida|85143|\n",
      "|   California|18322|\n",
      "|     New York|18120|\n",
      "|        Texas|12563|\n",
      "|Massachusetts| 7441|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# UNITED KINGDOM was the country most visitors came. They went to the following states most often:\n",
    "\n",
    "print('The country where most visitors came from was the United Kingdom. They traveled to the following states most often:')\n",
    "\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT US_State_Name, count(Year) as Count\n",
    "FROM final\n",
    "WHERE Origin_Country = 'UNITED KINGDOM'\n",
    "GROUP BY US_State_Name\n",
    "ORDER BY Count DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+-------+----------+---------------+\n",
      "|US_State_Name|Count|UK_Temp|State_Temp|Temp_Difference|\n",
      "+-------------+-----+-------+----------+---------------+\n",
      "|       Hawaii|  724|    8.2|     21.59|         -13.39|\n",
      "|      Florida|85143|    8.2|     21.49|         -13.29|\n",
      "|    Louisiana| 1659|    8.2|     19.86|         -11.66|\n",
      "|        Texas|12563|    8.2|     19.15|         -10.95|\n",
      "|  Mississippi|  121|    8.2|     18.38|         -10.18|\n",
      "+-------------+-----+-------+----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What is the difference in temperature between the UK and the US states traveled to\n",
    "# People could be traveling due to warm weather vacactions\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT US_State_Name, count(Year) as Count,\n",
    "    round(avg(Origin_Country_Temp),2) AS UK_Temp, round(avg(State_Temp),2) AS State_Temp,\n",
    "    round((avg(Origin_Country_Temp) - avg(State_Temp)), 2) AS Temp_Difference\n",
    "FROM final\n",
    "WHERE Origin_Country = 'UNITED KINGDOM'\n",
    "GROUP BY US_State_Name\n",
    "ORDER BY Temp_Difference\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|Visa_Type|Count|\n",
      "+---------+-----+\n",
      "|        2|80786|\n",
      "|        1| 4305|\n",
      "|        3|   52|\n",
      "+---------+-----+\n",
      "\n",
      "Visa types are:\n",
      "1 = Business\n",
      "2 = Pleasure\n",
      "3 = Student\n",
      "\n",
      "Appears most people travel to Florida for pleasure\n"
     ]
    }
   ],
   "source": [
    "# Based on temperature differences, people may travel to Florida from the UK for vacation\n",
    "# Look at types of visas to see what type of travel is being made to Florida\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT Visa_Type, count(Year) as Count\n",
    "FROM final\n",
    "WHERE Origin_Country = 'UNITED KINGDOM' AND US_State_Name = 'Florida'\n",
    "GROUP BY Visa_Type\n",
    "ORDER BY Count DESC\n",
    "\"\"\"\n",
    ").show()\n",
    "\n",
    "print('Visa types are:\\n1 = Business\\n2 = Pleasure\\n3 = Student\\n\\nAppears most people travel to Florida for pleasure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Two data quality tests:\n",
    "\n",
    "__Test 1__\n",
    "\n",
    "Check if all the primary keys used in the JOINs are unique. Since a primary key is a unique identifier, there should only be one of each in the column. This tests counts the number of times a category or value occurs in the primary key column, and will return values that do not pass the test of a unqiue value. If the tests return blank values then it passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Re-run code to create views for Spark SQL queries\n",
    "immigration_clean.createOrReplaceTempView('immigration')\n",
    "demo2.createOrReplaceTempView('demo')\n",
    "airports_spark.createOrReplaceTempView('airports')\n",
    "state_temp_clean.createOrReplaceTempView('state_temp')\n",
    "country_temp_clean.createOrReplaceTempView('country_temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|StateCode|Count|\n",
      "+---------+-----+\n",
      "+---------+-----+\n",
      "\n",
      "+---------+-----+\n",
      "|iata_code|Count|\n",
      "+---------+-----+\n",
      "+---------+-----+\n",
      "\n",
      "+----------+-----+\n",
      "|state_code|Count|\n",
      "+----------+-----+\n",
      "+----------+-----+\n",
      "\n",
      "+------------+-----+\n",
      "|country_code|Count|\n",
      "+------------+-----+\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test unique keys. \n",
    "# In order to pass, all queries should return none \n",
    "\n",
    "# StateCode from demographics test\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT StateCode, count(distinct(StateCode)) AS Count\n",
    "FROM demo\n",
    "GROUP BY StateCode\n",
    "HAVING Count > 1\n",
    "ORDER BY StateCode DESC\n",
    "\"\"\"\n",
    ").show()\n",
    "\n",
    "\n",
    "# iata_code from airports test\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT iata_code, count(distinct(iata_code)) AS Count\n",
    "FROM airports\n",
    "GROUP BY iata_code\n",
    "HAVING Count > 1\n",
    "ORDER BY iata_code DESC\n",
    "\"\"\"\n",
    ").show()\n",
    "\n",
    "# state_code from state temperatures test\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT state_code, count(distinct(state_code)) AS Count\n",
    "FROM state_temp\n",
    "GROUP BY state_code\n",
    "HAVING Count > 1\n",
    "ORDER BY state_code DESC\n",
    "\"\"\"\n",
    ").show()\n",
    "\n",
    "# country_code from country temperatures test\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT country_code, count(distinct(country_code)) AS Count\n",
    "FROM country_temp\n",
    "GROUP BY country_code\n",
    "HAVING Count > 1\n",
    "ORDER BY country_code DESC\n",
    "\"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "__Test 2__\n",
    "\n",
    "This test is to check if datatypes are still correct. Will check the date fields since these are the ones that changed from numbers to date. Want to ensure these data type conversions made it through the data wrangling process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Month', 'int'), ('Arrival_Date', 'date')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration_final.dtypes[2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file.\n",
    "\n",
    "\n",
    "See markdown file 'Data Dictionary.md' for "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "__Responses to Prompts__:\n",
    "\n",
    "I decided to use Spark since it is a framework for processing large amounts of data. This slice of the data was for one month's worth of data. It contained approximately 3 million rows and performing the work locally worked sufficiently. However, if we needed to process a year's worth of data or more, we would need more computing power. Since we already have the data pipeline coded using Spark's framework and syntax, we could quickly implement the pipeline using on premise or cloud based distributed computing solutions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "I propose to update the data on a monthly basis. This would allow for monthly analysis of immigration trends and to make decisions in a timely fashion. This data is not like a sales transaction database that needs to be processed much more frequently, and therefore the frequency of updates is sufficient. Under the proposal of monthly updates, analysts can still perform monthly reporting tasks while keeping costs low by processing the data 12 times a year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "I would handle the problem differently in the following when ways when presented with new challenges outline above:\n",
    "- Use an AWS EMR  to process larger amounts of data. This notebook only performed data pipeline <br> activities on one month of data so I was able to perform the tasks locally. If there is much more <br>data to be processed, utilizing distributed clusters on a cloud platform <br>would make much more sense and execute much faster. This would be much cheaper than investing <br>in on premise solutions and enable us to begin work much quicker.\n",
    "- I would use an automated scheduler/workflow manager such as Airflow. Airflow would allow us to schedule <br>ETL processes to execute in an automated fashion and provides great monitoring and data quality capabilities.\n",
    "- I would use a cloud datawarehouse product like Amazon Redshift. Since the data warehouse is in the cloud, <br>it is scalable solution if a lot of people need access or need to perform their own ad hoc analyses. It would also be <br>simple since each person can access it with their own credentials and perform queries. Redshift also<br> is capable of making connections to other tools like Jupyter, data visualization tools (Power BI, Tableau, Looker,etc.) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
